---
title: "GEM500: Carbon and Biomass estimation"
author: "Tommaso Trotto (tommaso.trotto@ubc.ca)"
affiliation: "University of British Columbia, Department of Forest Resource Management"
date: "06/24/2024"
bibliography: references.bib
format:
  html:
    page-layout: full
    code-fold: true
    theme: flatly
    toc: true
    toc-float: true
    toc-location: left
---

# Forest biomass and carbon via remote sensing

Forest worldwide are integral part of the carbon cycle as sinks and sources of carbon during processes such as growth, decay, disturbance, and renewal. Their role is to capture carbon in the form of CO<sub>2</sub> from the atmosphere through photosyntesis and fix it into more stable organic structures such as roots, stems, leaves, vascular system, as so forth in the form of bounded carbon (carbon chemically bounded to other elements such as hydrogen or nitrogen). On average, the fixed carbon is estimated to make up 50% of the tree biomass, while the rest is mostly water, to oversimplify. Disturbances such as insect infestations, windthrow, and fires instead cause forests to release carbon back into the atmosphere as CO<sub>2</sub>, either by burining the standing wood or initiating decomposition processes. For example, the fire season in 2023 in Canada resulted in the release of roughly 480 Mt of carbon, which corresponds to approaximately 23% of the global wildfire carbon emission for the year. A huge amount! This tells you how important it is to manage forests to limit or prevent the occurrence of these large-scale disturbances. So what can we do? In managed forests, forest interventions influence natural dynamics or carbon sequestring and release by planting, growing, or removing biomass.

As you may have hinted by now, it is crucial to keep track of carbon stocks at various scales, thus requiring different data sources, understand at what pace carbon moves, and what actors are involved in storing and releasing carbon, especially in face of exhacerbating disturbance regimes resulting from climate change. The heat around carbon has led to the development of various carbon models calibrated for specific objectives (e.g. sequestration/release) and/or site conditions (e.g. boreal forest/tropical forest). In particular, for this lab our focus is on carbon models to estimate the amount sequestred by standing vegetation. These models may take a variety of data types depending on the scale of application. For example, we could work with inventory-based models, where the data is pulled from inventory information regarding individual stands or the entire landscape. This is what the Carbon Budget Model of the Canadian Forest Sector (CBM-CFS3) does. An aspatial carbon model that takes data from the forest inventory to estimate carbon stocks and stock changes. CBM-CDF3 is the tool that is currently used by the CFS to report on the forest carbon balance of Canada's managed forests (where we have inventory data). However, we are now taking a remote sensing program, so why are we talking about aspatial data? At Loon Lake we worked with data sources and types to answer different questions, so we should try to apply those concepts here. Thankfully, other spatial models have been developed over the years to account for the greater availability or remotely sensed data that go outside managed forest boundaries.

# Physiological Process Predicting Growth (3PG)

Physiological Process Predicting Growth (3PG) is a model developed by @landsberg1997 and subsequentely extended by @coops1998 to allow remotely sensed data to be pulled in and therefore enlarge the scope and scale of the model. 3PG is a process-based model, which means it is deterministic in nature as it builds predictions based on a fixed series of well-known ecological processes that simulate the natural carbon dynamics in a forestry context, while having a clear ecological interpretations. The power of 3PG comes from ecological processes simplification, while maintaining their validity, and ability to scale with the data. 3PG is well suited for estimating biomass and carbon dynamics from newly grown forest patches. Meaning that 3PG really does its best at growing a forest from the ground up and gives you an estimate of stem, root, and foliage biomass at the end of a user-specified growth period. However, with this lab we are taking a step further by taking an historical perspective on 3PG and try to work out current biomass and carbon estimates assuming that the forest was planted many years ago. In a nutshell, we are going to try reconstructing highly simplified growth dynamics to get an estimate of today's carbon and biomass content of the forest in Malcom Knapp.

In summary, the lab is structured into 2 sections:

1. Use 3PG to model tree growth until the end of the century considering a newly planted stand
2. Take an historical perspective on Malcom Knapp's forests and try estimating the current biomass and carbon content

## Data sources and preparation

Before we dive in, we need to better understand at what scale 3PG operates and what data is therefore needed and where we could retrieve it from. The 3PG implementation we are going to use works is by @trotsiuk2020 (`r3PG`), works at montly steps, and requires:
-   Climate data (temperature and precipitation)
-   Photoshyntetically-active solar radiation (PAR)
-   Number of frost days (FD)
-   Available soil water column (ASW)
-   Soil fertility
-   Elevation data (DEM - Digital Elevantion Model)
-   Species growth parameters

Ok! That are quite a few things going on here. You may understand how not only do we need to gather this data from a multitude of sources, but also harmonize it into a format that works with `r3PG`. Thankfully, we already have almost all the data we need (@tbl-sources) in the form of raster layers at a 90m spatial resolution, we just need to prepare it. In addition to this data, `r3PG` requires specific input information we'll see down the road.

| Data               | Description                                       | Units     | Source             |
|--------------------|---------------------------------------------------|-----------|--------------------|
| Climate*           | Minimum and maxium temperature and precipitation  | Celcius   | @wang2016          |         
|                    | future predictions based on SSP2.                 | mm        |                    | 
|--------------------|---------------------------------------------------|-----------|                    |
| PAR*               | Amount of radiation that activates photosynthesis | MJ/m2/d   |                    |  
|                    | from 400 to 700 nm based on SSP2.                 |           |                    | 
|--------------------|---------------------------------------------------|-----------|                    | 
| FD*                | Number of frost days                              | days      |                    | 
|--------------------|---------------------------------------------------|-----------|                    | 
| ASW (max)          | Max depth of available soil water                 | mm        |                    | 
|--------------------|---------------------------------------------------|-----------|--------------------| 
| Soil fertility     | Soil fertility                                    |           |                    | 
|--------------------|---------------------------------------------------|-----------|--------------------| 
| DEM                | Elevation data from                               | m         | ASTER satellite    | 
|--------------------|---------------------------------------------------|-----------|--------------------| 
| Species Parameters | Species-specific growth parameters for species of |           | Various literature | 
|                    | interest                                          |           |                    | 
: Summary and description of data available to run `r3PG`. *Available at monthly time steps. {#tbl-sources}

The cool thing about `r3PG` is that it helps us keep track of carbon and biomass dynamics as our data varies over time, so in our case we could track it monthly! In addition to that, `r3PG` (as well as similar implementations) allows you to input source data predictions, like varying climate scenarios to observe how carbon and biomass change as climate changes. In this lab, we will first try to determine the amout of carbon stored at present and do a simple prediction on how it would change under a Shared Socioeconomic Pathway - 2 (SSP2) (@riahi2017) until the end of the century.

As mentioned earlier, one caveat you'll encounter with `r3PG` is the data format it requires to actually run the model in the background. Unfortunately, no raster data is directly supported, so we'll have to work around that and prepare our input data as required by this implementation, that is as `dataframes`. That means that every pixel in the raster layers will correspond to an entry in our dataframes. To maintain the spatial nature of the model, we'll have to sequentially run `r3PG` for each entry, such that each entry will have a corresponding carbon/biomass value and trend over time. Then, we transform these values back into a raster layer by assigning each estimate to a empty raster, conventionally starting from the top-left pixel to the bottom-right pixel.

## Part 1: Simulating forest growth

Let's get us started! We begin this first part of the lab by simulating tree growth from the ground up assuming that Malcom Knapp has been completely harvested and replanted at the beginning of the year. We begin by preparing our `sites`, that is the area where the trees are planted. A `site` for `r3PG` is defined by a set of attributes, including latitude, elevation, soil class, and ASW (minimum, maximum, initial) within a defined growth period. This growth period represents the period the tree will grow for on the site. If we wanted to grow the trees from the ground up, a task 3PG excels at, we would set the begin of the growing period to today until the year we want the model to stop simulating, which for this lab is the end of the century. Remember that for the entire length of the period you must have data because `r3PG` can not deal with missing attributes. Alternatively, for the sake of this lab, we can assign a constant value and assume it won't change throughout the growing period. For example, we are giving a soil class of 2 (i.e. sandy soil), an initial ASW equal to the max ASW, and a minimum ASW of 0 millimeter.

Note that, while there are many other ways to code this chunk (and the previous), what we present is a very straightforward way, especially if you do not feel super conmfortable with your coding skills.

``` {r libraries}
#| include: false

library(r3PG)
library(terra)
library(dplyr)
library(tidyr)
library(tidyverse)
library(reshape2)
library(purrr)
library(lubridate)
library(ggplot2)
library(parallel)
```

``` {r sites}
# time frame
period <- '2011-2040'
from <- '2024-01'
to <- '2100-01'

# latitude
lat <- rast('data/Lat.tif')
# store coordinates for later
coords <- crds(lat, na.rm = F)
names(lat) <- 'latitude'
lat <- terra::as.data.frame(lat, na.rm = F)

# elevation
dem <- rast('data/DEM.tif')
names(dem) <- 'altitude'
dem <- terra::as.data.frame(dem, na.rm = F)

# ASW
asw_max <- rast('data/ASW_Max.tif')
names(asw_max) <- 'asw_max'
asw_max <- terra::as.data.frame(asw_max, na.rm = F)
asw_min <- 0
asw_i <- asw_max
names(asw_i) <- 'asw_i'

# prepare sites
# the model wants all variable to be explicit
# if we don't have values, just report a constant
site <- data.frame(latitude = lat,
                   altitude = dem,
                   soil_class = 2,
                   asw_i = asw_i,
                   asw_min = asw_min,
                   asw_max = asw_max,
                   from = from,
                   to = to)
head(site)
```

Note how the raster layers were converted into `dataframes` and every single entry has `site` information associated to it to conserve the spatial nature of the model. Furthermore, some entries have NA values. We will see why we are keeping those later.

It's now time to prepare our "species" dataset! `r3PG` requires information on when the trees were planted, the planting density, the fertility of the soil, and what the initial seedling biomass was to start growing them. In Malcom Knapp we are primarily working with Douglas fir, Western red cedar, and Western hemlock, so we'll input values for all these species. We set the planting date to the beginning of the year because we are just starting growing the trees. We then assume an initial number of stem per hectares of 5000 (conservative), and a biomass partitioning among stem, root, and foliage equal to 6, 3, and 1 Mg/ha. Note that because we have 3 species, we'll have 3 different biomass/carbon estimates, one for each species.

.....As you may have noticed, we have an "age" layer for all forested land in Canada (@maltman2023) as part of the National Terrestrial Ecosystem Monitoring System series of datasets (@hermosilla2016). This data was redacted in 2023, so we'll have to correct for the current year as of January 2024......

``` {r species}
spp <- c('PSEU.MEN', 'THUJ.PLI', 'TSUG.HET')  # latin names

# soil fertility
ftl <- rast('data/FTL.tif')
names(ftl) <- 'fertility'
ftl <- terra::as.data.frame(ftl, na.rm = F)

# prepare species
species <- data.frame(spp1 = spp[1],
                      spp2 = spp[2],
                      spp3 = spp[3],
                      planted = "2024-07",
                      fertility = ftl,
                      stems_n = 1700,
                      biom_stem = 6,
                      biom_root = 3,
                      biom_foliage = 1)
# reshape dataset so all data is repeated for each species
# important for downstream tasks
species <- melt(species,
                id.vars=names(species)[4:ncol(species)],
                value.name='species') %>%
  select(-variable) %>%
  relocate(species)
head(species)
```

For now that's all we need for the tree species. Let's start working on the climate modifiers and input what the projected climate will be until the end of the century. This step will allow `r3PG` to develop carbon and biomass projections in line with well established climate scenarios. As mentioned earlier, we have data using a SSP2 scenario. Note that for simplicity, we are considering the the climate data between 2011 and 2040 remain constant until the end of the century. In a real-case situation, you would want to follow the 20-year climate normals and re-run the model for every 20-year period while "carrying over" the biomass from the previous period in order to continuously grow the trees (instead of starting from the ground up at every 20-year interval).

```{r climate}
#| warning: false
# I'll implement a function to make the code
# less lengthy, but any other approach would work
needed <- c('Tmin', 'Tmax', 'PPT', 'Rad', 'NFFD')
build <- function(need) {
  f <- list.files('./data/ssp2',
                pattern = paste0(need, '.*', period),
                full.names = T)
  # open each file
  dfs <- lapply(seq_along(f), function(i) {
    r <- rast(f[i])
    names(r) <- i
    r <- terra::as.data.frame(r, na.rm = F)
  })
  # merge into single dataframe and convert to long format
  out <- dfs %>% 
    bind_cols() %>% 
    melt() %>%
    rename(!!sym(need) := value) %>%
    select(-variable)
}
climate <- lapply(needed, function(need) {
  build(need)
})

# put them in a single dataframe that can be used later on
climate <- bind_cols(climate)

# rename to match r3PG expectations
names(climate) <- c('tmp_min', 'tmp_max', 'prcp', 'srad', 'frost_days')

head(climate)
```

Climate data is now ready! We are dealing with quite some data here. More than 100K records! Some will be NA values, but we'll deal with those later to maintain the order with which we collected the data in the first place. This is important to maintain the `r3PG` spatial nature. That is, each pixel has a record of data and each pixel will have a corresponding carbon/biomass value. Pretty cool!

We are down to the last step before running the model! Now it's time to input the species growth parameters. We don't need to know in details what all the parameters mean because there are lots. If you're interested, explore the data that comes with this lab or check `i_parameters` for a description of each. A parameter that is very important to know is quantum canopy efficiency (aka "alpha"). Simply put, this parameters regulates how efficient the foliage in the canopy is to utilize incoming solar radiation to photosynthesize nutrients. Changing this parameter by any small amount will have a large impact on the biomass/carbon predictions. In general, these parameters allow us to develop species-specific growth curves with an associated carbon/biomass content. This step of our implementation is pretty easy, the file is ready to go, so we simply import it and pick the species we are interested in.

``` {r parameters}
# species file
select_all <- c('parameter', spp)
param <- read_csv('data/Final_Parameters.csv', show_col_types = F) %>%
  select(all_of(select_all))
head(param)
```

## Model developement

It's finally time to dive in into the model itself! We have all the data we need, each record associated to a single pixel. One caveat we are going to face now is related to the spatial nature we seek to preserve from `r3PG`. In principle, 3PG was not developed to be a spatial model, but it can take remotely sensed data to extend its scope and become spatial (@coops1998). The workaround to that is to treat each pixel *individually* and get a value for each! To do so, we'll have to do some iterations and run the same model over and over for each pixel. This can be quite tedious if you're working with a large dataset, but our study area is pretty small, so it shouldn't be too bad. 

If you recall from earlier, we kept all NA values, why? Each raster layers we imported is likely to have a number of pixels with NA value for a variety of reasons. However, it is quite unlikely that every raster we imported has the exact same empty pixels Because we must non-empty records for every pixel, we first compile them all together, and during the model iterations we check for the presence of NA. If none, we continue to run it. This way, we preserve the original location of the pixel and avoid running the model if there are missing values. Note that this workaround is straightforward when you work with small amounts of data. When dealing with much larger datasets, you may need to figure out other ways to work this out, simply because of the amount of data you'd work with.

To work more efficiently, we will write a function to process each pixel sequentially, and then we'll do some simple code parallelization to take advantage of your machine's core and speed everything up a little. Running the model now is pretty straightforward. Just use the `run_3PG` function, so let's set this up. First, we'll do a single-pixel run to show you how this works if Douglas Fir were planted. Next, we will write the actual model call. We have to fix the climate data such that for 1 pixel we have 12 months of data, which will be repeated for all years until the end of the century. We are going to accomplish that with the `prepare_climate` function.

```{r pixel}
# year climate for 1 pixel
offset <- 8960
pixels <- sapply(0:11, function(i) 41 + (offset * i))
climate_pixel <- climate[pixels, ]
climate_pixel <- prepare_climate(climate_pixel, from = from, to = to)

# example on 1 non-empty pixel
output <- run_3PG(site = site[41,],
                  species = species[41, ],
                  climate = climate_pixel,
                  parameters = param[, 1:2],
                  check_input = T,
                  df_out = T)

# extract stem biomass and carbon
stem_bc <- output %>%
  filter(variable == 'biom_stem')
stem_bc$carbon <- stem_bc$value / 2
```

Great! We finally managed to run 3PG until the end of the century! As you can observe from the output, we have biomass and carbon values in Mg/ha at the end of each month. Let's do some plotting to better see what the trend is over time if Malcom Knapp were planted with only Douglas Fir (@fig-biomass).

```{r plot}
#| label: fig-biomass
#| fig-cap: "Biomass Growth for Douglas Fir from 2024-01 to 2100-01 for 1 pixel in Malcol Knapp"
#| echo: false

p <- ggplot(stem_bc, aes(date, value)) +
  geom_line(linewidth = 1) +
  theme_classic() +
  labs(x = "Years", y = "Biomass (Mg/ha)")
p
```

It seems we are seeing a nice increase in biomass over time, with a plateau around year 2060. Why is that?

Now to a more fun task. We have to repeat this operation for every single pixel in the area. Let's write a function to do all this and run it for every pixel. We are going to produce quite a few new data here. In the code chunk below we are simply going to repeat what we did for the single-pixel run, and then run multiple instances of it for each pixel, assuming that the only species present if Douglas Fir. We will then make a map of the predicted biomass in January 2010. To do so, we will have to create a new raster object starting from the biomass dataframe we have. You can achieve this with the package `terra` that we previously used.

``` {r model}
# prepare function to run the model
# we repeat the same code of above for simplicity
run_model <- function(pixel) {
  # if empty, don't run
  if (isFALSE(complete.cases(site[pixel, ]))) {
    df_null <- data.frame(date = as.Date('1900-01-01'),
                          species = spp[1],
                          group = 'stocks',
                          variable = 'biom_stem',
                          value = NA)
    return(df_null)
  }
  # prepare climate data for site
  pixels <- sapply(0:11, function(i) 41 + (offset * i))
  climate_pixel <- climate[pixels, ]
  climate_pixel <- prepare_climate(climate_pixel, from = from, to = '2100-01')
  output <- run_3PG(site = site[pixel,],
                    species = species[pixel, ],
                    climate = climate_pixel,
                    parameters = param[, 1:2],
                    check_input = T,
                    df_out = T)
  stem_bc <- output %>%
    filter(variable == 'biom_stem')
  return(tail(stem_bc, 1))  # year 2100
}

# run the model for every pixel
# let's take advantage of more cores in your machine to speed everything up
output <- mclapply(seq_len(nrow(site)),
                   run_model,
                   mc.cores = 10,
                   mc.cleanup = T) %>%
  bind_rows()

# make a raster object
r <- output %>%
  select(value) %>%
  rename(z = value) %>%
  mutate(x = coords[, 1],
         y = coords[, 2],
         .before = z) %>%
  rast(type='xyz', crs='epsg:3005')

plot(r, legend = T, main = "Biomass prediction (Mg/ha) for Douglas Fir in Malcom Knapp in 2100.")
```

To repeat this analysis for the other species, we run the same code but change the input species. If you want to be more fancy, you can re-write the function to accept multiple species and output a raster stack, that is a collection of rasters with the same coordinate reference system, extend, and resolution stored in a single object.


## Part 2: Historical biomass reconstruction

Now that we have completed the first part of the lab, recall we want to know what is today's biomass across Malcolm Knapp. To do that using 3PG, we have to reconstruct the history of the site



### References

::: {#refs}
:::























